# Benchmark classification on MNIST

## Описание
Проект сравнивает несколько классических алгоритмов классификации на рукописных
цифрах MNIST и показывает, как оценивать их качество через кросс‑валидацию и
матрицу ошибок. Отдельно рассматривается влияние L1/L2‑регуляризации в
логистической регрессии и подбор гиперпараметров случайного леса.

## Небольшая теория
- kNN классифицирует по ближайшим соседям в пространстве признаков.
- Логистическая регрессия — линейная модель, а регуляризация L1/L2 контролирует
  сложность: L1 делает веса разреженными, L2 сглаживает веса.
- Random Forest — ансамбль деревьев решений, снижает переобучение за счет усреднения.
- Кросс‑валидация помогает оценить качество модели стабильнее, чем один сплит.

## Связь файлов
- `mnist.ipynb` — сравнение базовых моделей и визуализация ошибок.
- `l1_l2_logreg.ipynb` — сравнение L1/L2 и визуализация весов модели.
- `rf_hyperparams.ipynb` — подбор гиперпараметров Random Forest через GridSearch.
- `functions.py` — общие функции для валидации и визуализаций.

## Как запустить
1. Открыть нужный ноутбук в Jupyter/VS Code.
2. Выполнить ячейки по порядку (данные MNIST будут скачаны автоматически).

## Требования
- Python 3.8+ — интерпретатор Python.
- numpy — работа с массивами и вычисления.
- matplotlib — визуализация и матрицы ошибок.
- scikit-learn — модели, разбиение, метрики и MNIST.

## Резюме
Реализован в рамках курса «Введение в машинное обучение» как практикум по сравнению
классификаторов, кросс‑валидации и регуляризации. Практическое знакомство с тем,
как сравнивать модели на одной задаче.

